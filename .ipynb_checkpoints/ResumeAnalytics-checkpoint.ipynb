{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automated  Basic Cleaning\n",
    "# All of this should be re-exported back into the CSV before distributing iot \n",
    "\n",
    "df = pd.read_csv(\"Resume.csv\").applymap(lambda s:s.lower().strip() if type(s) == str else s)\n",
    "df = df[df[\"startyear\"] != 2011]\n",
    "df[\"skills\"] = df[\"skills\"].str.replace(\" \", \"\")\n",
    "\n",
    "def isUs(country):\n",
    "    return type(country) is str and \"canada\" not in country and (\", ca\" in country or \", wa\" in country or \", ny\" in country or \", nj\" in country)\n",
    "\n",
    "# Data Tagging whether internships are from USA or not \n",
    "df[\"is_us_1\"] = df[\"location1\"].map(isUs)\n",
    "df[\"is_us_2\"] = df[\"location2\"].map(isUs)\n",
    "df[\"is_us_3\"] = df[\"location3\"].map(isUs)\n",
    "df[\"is_us_4\"] = df[\"location4\"].map(isUs)\n",
    "df[\"is_us_5\"] = df[\"location5\"].map(isUs)\n",
    "df[\"is_us_6\"] = df[\"location6\"].map(isUs)\n",
    "\n",
    "# Remove newlines in role descriptions\n",
    "df[\"roles1\"] = df[\"roles1\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "df[\"roles2\"] = df[\"roles2\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "df[\"roles3\"] = df[\"roles3\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "df[\"roles4\"] = df[\"roles4\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "df[\"roles5\"] = df[\"roles5\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "df[\"roles6\"] = df[\"roles6\"].str.replace(\"\\n\", \" \").str.replace(\"  \", \" \")\n",
    "\n",
    "# Construct # of internship Field\n",
    "df[\"numcoops\"] = 1\n",
    "df.loc[~df[\"company2\"].isnull(), \"numcoops\"] = 2\n",
    "df.loc[~df[\"company3\"].isnull(), \"numcoops\"] = 3\n",
    "df.loc[~df[\"company4\"].isnull(), \"numcoops\"] = 4\n",
    "df.loc[~df[\"company5\"].isnull(), \"numcoops\"] = 5\n",
    "df.loc[~df[\"company6\"].isnull(), \"numcoops\"] = 6\n",
    "df[\"numcoops_noisy\"] = df[\"numcoops\"] + np.random.normal(0, 0.1, len(df))\n",
    "df[\"startyear_noisy\"] = df[\"startyear\"] + np.random.normal(0, 0.1, len(df))\n",
    "\n",
    "df.loc[df[\"avggpa\"] < 5, \"gpa\"] = df[\"avggpa\"]\n",
    "df.loc[df[\"avggpa\"] > 5, \"pctgrades\"] = df[\"avggpa\"]\n",
    "del df[\"avggpa\"]\n",
    "df.to_csv(\"resume2.csv\")\n",
    "# TODO: Need to anonymize names\n",
    "# TODO: Reverse company order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: Intro to Jupyter Notebook Environment & DataFrame Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_apps = 50\n",
    "interviews = last_apps * 0.1\n",
    "reject = last_apps - interviews\n",
    "print(last_apps, interviews, reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 \n",
    "case1_apps = 50 * 1.1 \n",
    "case1_interviews = case1_apps * 0.1\n",
    "case1_reject = case1_apps - case1_interviews\n",
    "print(case1_apps, case1_interviews, case1_reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 \n",
    "case2_apps = 50\n",
    "case2_reject = 45 * 0.9\n",
    "case2_interviews = case2_apps - case2_reject\n",
    "print(case2_apps, case2_interviews, case2_reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(data =  {'col1': [None, \"I\", \"like\", \"cake\", \"and\", \"pie\"], \n",
    "                           'col2': [1, 1, None, 1, 1, None],\n",
    "                           'col3': [2, 1, 2, 1, 2, 1]})\n",
    "# demo the following operations and breifly explain what they do \n",
    "_df \n",
    "_df[\"col1\"].describe()\n",
    "_df[\"col3\"].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Validation\n",
    "\n",
    "\n",
    "Check GPA & Average. Estimated time:  3 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpa = df[\"gpa\"]\n",
    "gpa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = df[\"pctgrades\"]\n",
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways from task 1\n",
    "- Don't use GPA or Average in your analysis. There isn't enough data on people with <80 average "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2: Series Operations & Intro to MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(data =  {'col1': [None, \"I\", \"like\", \"cake\", \"and\", \"pie\"], \n",
    "                           'col2': [1, 1, None, 1, 1, None],\n",
    "                           'col3': [2, 1, 2, 1, 2, 1], \n",
    "                           'col4': [1, None, 3, 4, 5, 6],\n",
    "                           'col5': [1, 2, 4, None, 16, 32]})\n",
    "_df.to_csv(\"testdata1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df[\"col4\"]\n",
    "_df[\"col5\"]\n",
    "_df[\"col4\"] + _df[\"col5\"]\n",
    "n1 = np.random.normal(0, 0.1, len(_df))\n",
    "n2 = np.random.normal(0, 0.1, len(_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(_df[\"col4\"] + n1, _df[\"col5\"] + n2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: More Data Validation \n",
    "\n",
    "Plot number of Internships vs Start Year. Estimated time: 3 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numcoops\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_start_year = df[~df[\"startyear\"].isnull()]\n",
    "\n",
    "X = has_start_year[\"startyear\"]\n",
    "Y = has_start_year[\"numcoops\"]\n",
    "plt.scatter( X, Y)\n",
    "# Linear regression is too hard, don't bother with trying to explain it or demo it \n",
    "# plt.plot( X.reshape(-1,1), LinearRegression().fit(X.reshape(-1,1), Y.reshape(-1,1)).predict(X.reshape(-1,1)) )\n",
    "plt.xlabel(\"Start Year\")\n",
    "plt.ylabel(\"# of Internships\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways From Task 2:\n",
    "\n",
    "- Generally, you would have had more internships the earlier you started University. This is in line with our expectations. So NumInternships and StartYear fields are probably okay to use in our analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 3 - Concatenating Series & counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[\"col4\"].append(_df[\"col5\"])\n",
    "_df[\"col3\"].head(2)\n",
    "_df[\"col3\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - What places hire a lot of UW kids?\n",
    "\n",
    "Given that co-op apps close in 2 days, people might be wondering where they should apply. We attempt to answer the following questions: \n",
    "\n",
    "- Which places hire a lot of interns? (Get hired) \n",
    "- Which places hire a lot of first year interns? (some places discriminate against first year kids) \n",
    "- Find places where people are likely to return? (Be happy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companies = df[\"company1\"]\n",
    "companies = companies.append(df[\"company2\"])\n",
    "companies = companies.append(df[\"company3\"])\n",
    "companies = companies.append(df[\"company4\"])\n",
    "companies = companies.append(df[\"company5\"])\n",
    "companies = companies.append(df[\"company6\"])\n",
    "companies.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 4 - Conditional Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df[\"col1\"].isnull()\n",
    "~_df[\"col1\"].isnull()\n",
    "_df[\"col3\"] == 2\n",
    "_df[\"col3\"] == 2 & _df[\"col2\"].isnull()\n",
    "_df[_df[\"col3\"] == 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4:  What places hire a lot of first years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_coops = df[df[\"numcoops\"] == 1][\"company1\"]\n",
    "two_coops = df[df[\"numcoops\"] == 2][\"company2\"]\n",
    "three_coops = df[df[\"numcoops\"] == 3][\"company3\"]\n",
    "four_coops = df[df[\"numcoops\"] == 4][\"company4\"]\n",
    "five_coops = df[df[\"numcoops\"] == 5][\"company5\"]\n",
    "six_coops = df[df[\"numcoops\"] == 6][\"company6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_coops.append(two_coops).append(three_coops).append(four_coops).append(five_coops).append(six_coops).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punted task 5:  What places hire a lot of interns who return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = df[df[\"company1\"] == df[\"company2\"]][\"company1\"]\n",
    "return2 = df[df[\"company2\"] == df[\"company3\"]][\"company2\"]\n",
    "return3 = df[df[\"company3\"] == df[\"company4\"]][\"company3\"]\n",
    "return4 = df[df[\"company4\"] == df[\"company5\"]][\"company4\"]\n",
    "return5 = df[df[\"company5\"] == df[\"company6\"]][\"company5\"]\n",
    "return1.append(return2).append(return3).append(return4).append(return5).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways from tasks 3, 4 and 5 \n",
    "- Shopify is probably a good place for first years to apply - they hire many waterloo kids, many first year waterloo kids, and people are happy there\n",
    "- If I don't get google or Cali for my first co-op, that's pretty common. In fact, most first co-ops work in Canada companies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 4 - Working with Strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Most popular skills among students\n",
    "\n",
    "As a student, I want to improve my chances of being employed. Given that I'm at a hackathon and can learn lots of cool new stuff this weekend, what should I learn to maximize my chances? We wish to answer the following questions \n",
    "\n",
    "- What skills are most popular among students? \n",
    "- What skills are most used in jobs?\n",
    "- What skills are most likely to get me Cali? <- probably getting punted not doing this cause it's kinda toxic\n",
    "\n",
    "\n",
    "Students led - 6 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess datasets \n",
    "skills = df[\"skills\"].fillna(\"\")\n",
    "ranked_skills_list = skills.apply(lambda x: pd.value_counts(x.split(\",\")) )\n",
    "ranked_skills_list.to_csv(\"skills_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranked_roles_list = pd.read_csv(\"skills_data.csv\")\n",
    "\n",
    "skills_summed = ranked_skills_list.sum(axis = 0).sort_values(ascending=False)\n",
    "# Maybe a more simpler version?\n",
    "#ranked_skills_list = pd.Series(skills.str.cat(sep=\",\").split(\",\")).value_counts()\n",
    "skills_summed.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - What skills do a lot of people use on their jobs?\n",
    "\n",
    "Knowing what skills are popular are great, but what if that many students list a bunch of useless languages on their resume (eg: scheme)? We should instead be asking what are people hiring co-ops to do\n",
    "\n",
    "I really want them to run this analysis on their own, hopefully this isn't too hard :/. I guess I can hand-hold them into solving it with demo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roles_list = pd.Series()\n",
    "for idx, r in df.iterrows():\n",
    "    roles = str(r[\"roles1\"])\n",
    "    if r[\"numcoops\"] > 2:\n",
    "        roles = roles + \" \" + str(r[\"roles2\"])\n",
    "    if r[\"numcoops\"] > 3:\n",
    "        roles = roles + \" \" + str(r[\"roles3\"])\n",
    "    if r[\"numcoops\"] > 4:\n",
    "        roles = roles + \" \" + str(r[\"roles4\"])\n",
    "    if r[\"numcoops\"] > 5:\n",
    "        roles = roles + \" \" + str(r[\"roles5\"])\n",
    "    if r[\"numcoops\"] > 6:\n",
    "        roles = roles + \" \" + str(r[\"roles6\"])\n",
    "    \n",
    "    words = roles.split(\" \")\n",
    "    sk = \" \"\n",
    "    for w in words:\n",
    "        w = w.strip()\n",
    "        if w in ranked_skills_list and w != \"\":\n",
    "            sk = sk + \",\" + w\n",
    "    roles_list.set_value(idx, sk[1:])\n",
    "ranked_roles_list = roles_list.apply(lambda x: pd.value_counts(x.split(\",\")) )\n",
    "ranked_roles_list.to_csv(\"roles_data.csv\", index=False)\n",
    "\n",
    "# ranked_roles_list = roles.apply(lambda x: pd.value_counts(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_roles_list = pd.read_csv(\"roles_data.csv\")\n",
    "\n",
    "duties_summed = ranked_roles_list.sum(axis = 0).sort_values(ascending=False)\n",
    "# Maybe a more simpler version?\n",
    "#ranked_skills_list = pd.Series(skills.str.cat(sep=\",\").split(\",\")).value_counts()\n",
    "duties_summed.head(20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skills_and_duties = pd.concat([ranked_skills_list, ranked_roles_list], axis=1, keys=[\"skills\", \"roles\"])\n",
    "# skills_and_duties = skills_and_duties.loc[~skills_and_duties[\"skills\"].isnull() & ~skills_and_duties[\"roles\"].isnull()]\n",
    "# skills_and_duties.sort_values(by=[\"skills\"], ascending=False)\n",
    "# skills_and_duties.sort_values(by=[\"roles\"], ascending=False)\n",
    "# Maybe plot the top 10 skills if we have time? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways from Task 7\n",
    "\n",
    "- iOS and Android dev is useful for many jobs, but many people do not have it as a skill. Mobile dev may be a good niche to get into if you want the least competiton when applying for jobs ;) \n",
    "- For those interested in data, Spark may  be a good framework to learn \n",
    "- C++ is known by many people, but not many jobs are using C++. The oppositie is true for Golang\n",
    "- Python is quite a popular language to learn and also use on the job \n",
    "- Docker doesnt seem that popular in terms of co-op jobs (may imply DevOps jobs are rare). Validate this hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Help me understand what a data scientist does  \n",
    "### May be punted because of not enough time\n",
    "People like to hype up machine learning. What do machine learning interns do? Is that something I'm interested in? Let's use data to find out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 6 - What's a DS anyway? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_data = df[df[\"type\"]== \"ds\"][['skills', 'roles1', 'roles2', 'roles3', 'roles4', 'roles5', 'roles6','projdesc1','projdesc2','projdesc3','projdesc4','projdesc5']]\n",
    "ds_data.to_csv(\"ds_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - What percentage of DS are working in US? What percentage of non-DS are working in US?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_people = df[df[\"type\"]==\"ds\"]\n",
    "non_ds_people = df[df[\"type\"]!=\"ds\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = ds_people[~ds_people[\"company1\"].isnull()][\"is_us_1\"]\n",
    "job2 = ds_people[~ds_people[\"company2\"].isnull()][\"is_us_2\"]\n",
    "job3 = ds_people[~ds_people[\"company3\"].isnull()][\"is_us_3\"]\n",
    "job4 = ds_people[~ds_people[\"company4\"].isnull()][\"is_us_4\"]\n",
    "job5 = ds_people[~ds_people[\"company5\"].isnull()][\"is_us_5\"]\n",
    "job6 = ds_people[~ds_people[\"company6\"].isnull()][\"is_us_6\"]\n",
    "\n",
    "ds_jobs = job1.append(job2).append(job3).append(job4).append(job5).append(job6)\n",
    "ds_jobs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = non_ds_people[~non_ds_people[\"company1\"].isnull()][\"is_us_1\"]\n",
    "job2 = non_ds_people[~non_ds_people[\"company2\"].isnull()][\"is_us_2\"]\n",
    "job3 = non_ds_people[~non_ds_people[\"company3\"].isnull()][\"is_us_3\"]\n",
    "job4 = non_ds_people[~non_ds_people[\"company4\"].isnull()][\"is_us_4\"]\n",
    "job5 = non_ds_people[~non_ds_people[\"company5\"].isnull()][\"is_us_5\"]\n",
    "job6 = non_ds_people[~non_ds_people[\"company6\"].isnull()][\"is_us_6\"]\n",
    "\n",
    "\n",
    "non_ds_jobs = job1.append(job2).append(job3).append(job4).append(job5).append(job6)\n",
    "non_ds_jobs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 / (31+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "73 / (73 + 236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of internships of DS and non DS people \n",
    "ds_people[\"numcoops\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ds_people[\"numcoops\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 7 - What skills do DS people know? \n",
    "There really isn't any new commands here. Just copy paste a previous command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skills = ds_people[~ds_people[\"skills\"].isnull()][\"skills\"]\n",
    "ranked_skills_list = skills.apply(lambda x: pd.value_counts(x.split(\",\"))).sum(axis = 0).sort_values(ascending=False)\n",
    "ranked_skills_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Understanding limitations in our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly talk about how the data was collected (google search \"uwaterloo intern filetype:pdf\")\n",
    "Explain why the following two questions cannot be answered: \n",
    "\n",
    "- Are DS people more likely to have personal websites than SWE people? (bad data collection method, implies everyone has website)\n",
    "- When applying to Microsoft, does being in SYDE put you at a disadvantage? (causation) \n",
    "\n",
    "Then, show the next few questions and see whether people think we're able to answer \n",
    "#### Questions that we cannot answer given our data: \n",
    "- Are UW students more likely to work in USA than UofT students? (Missing data) \n",
    "- Do people with lower grades have less chances of getting PM? (not enough clear grade / GPA data) \n",
    "- Do short people have better jobs than tall people? (require causation, correlation is not useful. Also missing data on height) \n",
    "\n",
    "#### Questions that we can answer with our data:\n",
    "- Are DS more likely to have Githubs URLs than non-DS people on their resume? What about LinkedIn profiles on their resumes? \n",
    "- Out of the phone numbers people put on their resume, how many of them have are from Toronto? (Hint:  Toronto has area codes 416 / 647 / 437)? \n",
    "- Is a person's average 3rd internship more likely to be in USA or Canada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Summary: \n",
    "\n",
    "- Understanding data is not always intuitive. Data Analysts extract value ouf of data, which is not always easy   \n",
    "- Small improvements may have large downstream impacts (10% drop in rejections -> double # interviews) \n",
    "- Data analytics deals with taking data and extracting information. The usefulness of the information depends on us asking insightful questions we care about \n",
    "- Pandas and numpy deal with matricies (which are arrays of arrays). Manipulating these arrays help us extract information\n",
    "- First step of data analytics typically involves cleaning data and sanity checking our data to make sure we don't arrive at false conclusions\n",
    "- Plotting is possible with MatPlot lib, and can be helpful in data analytics\n",
    "- Sometimes, our questions cannot be answered from our data. In which case, we probably will need to collect more data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to count skills - This won't be used \n",
    "# Clean - Will probably be provided\n",
    "skillCounter = pd.DataFrame(skills, index=[\"count\"])\n",
    "\n",
    "for skilllist in df[\"kills\"]:\n",
    "    for k, v in skillCounter.items():\n",
    "        if \" \"+k+\" \" in skilllist or  \" \"+k+\", \" in skilllist:\n",
    "            skillCounter[k] = skillCounter[k] + 1\n",
    "    \n",
    "skillCounter.transpose().sort_values([\"count\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternative way to count skills - This won't be used \n",
    "# Clean - Will probably be provided\n",
    "df[\"Skills (list all skills as distinct words)\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Get a list of skills\n",
    "skillsCount = {}\n",
    "for skilllist in df[\"Skills (list all skills as distinct words)\"]:\n",
    "    skills = skilllist.split(\",\")\n",
    "    if len(skilllist) < 5:\n",
    "        continue\n",
    "    for skill in skills:\n",
    "        skill=skill.strip()\n",
    "        skillsCount[skill] = skillsCount.get(skill, 0) + 1\n",
    "skills = {k: 0 for k, v in sorted(skillsCount.items(), key=lambda x:x[1], reverse=True) if v >= 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skillCounter = pd.DataFrame(skills, index=[\"count\"])\n",
    "\n",
    "jobs = df[\"Job Roles (May be large paragraph)\\n\"]\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.1\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.2\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.3\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.4\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.5\"], ignore_index=True)\n",
    "jobs = jobs.dropna()\n",
    "\n",
    "for skilllist in jobs:\n",
    "    skilllist = skilllist.lower()\n",
    "    for k, v in skillCounter.items():\n",
    "        if \" \"+k+\", \" in skilllist or \" \"+k+\" \" in skilllist:\n",
    "            skillCounter[k] = skillCounter[k] + 1\n",
    "    \n",
    "skillCounter.transpose().sort_values([\"count\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 5 - Combining Series \n",
    "bobas[~bobas[\"onezo\"].isnull() & ~bobas[\"alley\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review4 = \"The Alley is my go to place when I'm feeling like having a nice cup of iced milk tea! \"\n",
    "review5 = \"The Deerioca fever drink is really good but the classic milk tea is not. \"\n",
    "review6 = \"I love this place! Best bubble tea in the business. They also have diary free options so that's a big plus for me. \"\n",
    "s1 = pd.Series((review1 + \" \" +review2 + \" \" + review3).split(\" \")).value_counts()\n",
    "s1\n",
    "s2 = pd.Series((review4 + \" \" +review5 + \" \" + review6).split(\" \")).value_counts()\n",
    "s2\n",
    "pd.concat([s1, s2], keys=[\"onezo\", \"alley\"])\n",
    "pd.concat([s1, s2], keys=[\"onezo\", \"alley\"])[\"onezo\"]\n",
    "bobas = pd.concat([s1, s2], axis=1, keys=[\"onezo\", \"alley\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review1 = \" The tapioca is made fresh in house making it easily the best I've had at a bubble tea shop.\"\n",
    "review2 = \" I love OneZo, it is easily the best bubble tea Iâ€™ve had so far, and the tapioca is delicious.\"\n",
    "review3 = \" Iconic place, i've been here way too many times. I love all their fruit bubble teas. \"\n",
    "\n",
    "onezo = pd.Series([review1, review2, review3])\n",
    "onezo.str.lower()\n",
    "onezo.str.contains(\"boba\") # False\n",
    "onezo.str.contains(\"bubble\") #[T, T, T]\n",
    "\n",
    "onezo.str.cat(sep=\" \") # Py String\n",
    "onezo.str.cat(sep=\" \").split(\" \") # Py Array\n",
    "pd.Series(onezo.str.cat(sep=\" \").split(\" \")) # Series\n",
    "pd.Series(onezo.str.cat(sep=\" \").split(\" \")).value_counts()\n",
    "# Consider talking about stemming / stop word filtering here\n",
    "\n",
    "# Review value counts \n",
    "companies\n",
    "companies.value_counts().sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
