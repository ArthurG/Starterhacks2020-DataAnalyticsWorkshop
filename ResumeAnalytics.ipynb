{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automated  Basic Cleaning\n",
    "# All of this should be re-exported back into the CSV before distributing iot \n",
    "\n",
    "df = pd.read_csv(\"Resume.csv\", skiprows=[0]).applymap(lambda s:s.lower().strip() if type(s) == str else s)\n",
    "df = df[df[\"Start Year\"] != 2011]\n",
    "df[\"Skills (list all skills as distinct words)\"] = df[\"Skills (list all skills as distinct words)\"].str.replace(\" \", \"\")\n",
    "\n",
    "def isUs(country):\n",
    "    return type(country) is str and \"canada\" not in country and (\", ca\" in country or \", wa\" in country or \", ny\" in country or \", nj\" in country)\n",
    "\n",
    "# Data Tagging whether internships are from USA or not \n",
    "df[\"is_us_0\"] = df[\"Company Location\\n\"].map(isUs)\n",
    "df[\"is_us_1\"] = df[\"Company Location\\n.1\"].map(isUs)\n",
    "df[\"is_us_2\"] = df[\"Company Location\\n.2\"].map(isUs)\n",
    "df[\"is_us_3\"] = df[\"Company Location\\n.3\"].map(isUs)\n",
    "df[\"is_us_4\"] = df[\"Company Location\\n.4\"].map(isUs)\n",
    "df[\"is_us_5\"] = df[\"Company Location\\n.5\"].map(isUs)\n",
    "\n",
    "# TODO: Need to Clean GPA manually from CSV\n",
    "# TODO: Need to anonymize names\n",
    "# TODO: Reverse company order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Data Validation & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Internships vs Start Year \n",
    "Student Run - 3 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct # of internship Field\n",
    "\n",
    "df[\"NumInternships\"] = 1\n",
    "df.loc[~df[\"Company Name\\n.1\"].isnull(), \"NumInternships\"] = 2\n",
    "df.loc[~df[\"Company Name\\n.2\"].isnull(), \"NumInternships\"] = 3\n",
    "df.loc[~df[\"Company Name\\n.3\"].isnull(), \"NumInternships\"] = 4\n",
    "df.loc[~df[\"Company Name\\n.4\"].isnull(), \"NumInternships\"] = 5\n",
    "df.loc[~df[\"Company Name\\n.5\"].isnull(), \"NumInternships\"] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out outliers with too many internships given start date and manually fix the data. Use df[df[\"Start Year\"] == 2018]\n",
    "df_clone = df.copy(deep=True)\n",
    "df_clone = df_clone.dropna(subset=[\"Start Year\"])\n",
    "\n",
    "X = df_clone[\"Start Year\"]\n",
    "Y = df_clone[\"NumInternships\"]\n",
    "plt.scatter( X  + np.random.normal(0, 0.1, len(df_clone)), Y + np.random.normal(0, 0.1, len(df_clone)))\n",
    "# Linear regression is too hard, don't bother with trying to explain it or demo it \n",
    "# plt.plot( X.reshape(-1,1), LinearRegression().fit(X.reshape(-1,1), Y.reshape(-1,1)).predict(X.reshape(-1,1)) )\n",
    "plt.xlabel(\"Start Year\")\n",
    "plt.ylabel(\"# of Internships\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check GPA \n",
    "Student Run - 3 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # TODO: Think about whether we want to use .loc instead \n",
    "\n",
    "gpa_people = df[df[\"Average or GPA  \"] < 5]\n",
    "gpa = gpa_people[\"Average or GPA  \"]\n",
    "gpa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_people = df[df[\"Average or GPA  \"] > 5]\n",
    "grades = grades_people[\"Average or GPA  \"]\n",
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Asking dataset what skills I should get \n",
    "\n",
    "As a student, I may wonder What skills do I learn if I want to be employed? That's a pretty broad question, so instead we'll answer some more specific q's instead:  \n",
    "\n",
    "- What skills are most popular among upper year students? \n",
    "- What skills are most used in jobs?\n",
    "- What skills are most likely to get me Cali? <- probably not doing this cause it's lowkey kinda toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What skills do a lot of people know?\n",
    "Students led - 3 minute \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = df[\"Skills (list all skills as distinct words)\"]\n",
    "skills = skills.loc[~skills.isnull()]\n",
    "# This last command is kinda challenging, think about how to show em how to write \n",
    "ranked_skills_list = skills.apply(lambda x: pd.value_counts(x.split(\",\"))).sum(axis = 0).sort_values(ascending=False)\n",
    "ranked_skills_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What skills do a lot of people use on their jobs?\n",
    "I really want students to run this analysis on their own, but may be too hard :/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Clean up roles - newlines are screwing up our analysis \n",
    "\n",
    "roles = df[\"Job Roles (May be large paragraph)\\n\"]\n",
    "roles = roles.append(df[\"Job Roles (May be large paragraph)\\n.1\"], ignore_index=True)\n",
    "roles = roles.append(df[\"Job Roles (May be large paragraph)\\n.2\"], ignore_index=True)\n",
    "roles = roles.append(df[\"Job Roles (May be large paragraph)\\n.3\"], ignore_index=True)\n",
    "roles = roles.append(df[\"Job Roles (May be large paragraph)\\n.4\"], ignore_index=True)\n",
    "roles = roles.append(df[\"Job Roles (May be large paragraph)\\n.5\"], ignore_index=True)\n",
    "\n",
    "\n",
    "roles = roles.loc[~roles.isnull()]\n",
    "ranked_roles_list = roles.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).sort_values(ascending=False)\n",
    "skills_and_duties = pd.concat([ranked_skills_list, ranked_roles_list], axis=1, keys=[\"skills\", \"duties\"])\n",
    "skills_and_duties = skills_and_duties.loc[~skills_and_duties[\"skills\"].isnull() & ~skills_and_duties[\"duties\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_and_duties.sort_values(by=[\"skills\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_and_duties.sort_values(by=[\"duties\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key insights : \n",
    "- Golang and Android is used by many companies, but many people do not have it as a skill\n",
    "- For those interested in data, Spark may  be a good first framework to learn \n",
    "- C++ is known by many people, but not many jobs are using C++\n",
    "- Python is quite popular language to learn and also use on the job \n",
    "- Docker doesnt seem that popular in terms of co-op jobs (may imply DevOps jobs are rare). Validate this hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 3: Asking dataset where should I apply? \n",
    "\n",
    "While developing skills may be helpful, that's not every helpful given that co-op deadline is coming up in XXX weeks. Instead, people may wonder where they should apply given their current situation: \n",
    "\n",
    "- Which places hire a lot of interns? (Get hired) \n",
    "- Which places hire a lot of first year interns? (some places discriminate against first year kids) \n",
    "- Find places where people are likely to return? (Be happy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What places hire a lot of UW kids?\n",
    "\n",
    "Student Led - 3 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companies = df[\"Company Name\\n\"]\n",
    "companies = companies.append(df[\"Company Name\\n.1\"])\n",
    "companies = companies.append(df[\"Company Name\\n.2\"])\n",
    "companies = companies.append(df[\"Company Name\\n.3\"])\n",
    "companies = companies.append(df[\"Company Name\\n.4\"])\n",
    "companies = companies.append(df[\"Company Name\\n.5\"])\n",
    "companies = companies.loc[~companies.isnull()]\n",
    "companies.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What places hire a lot of first years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_coops = df[df[\"NumInternships\"] == 1][\"Company Name\\n\"]\n",
    "two_coops = df[df[\"NumInternships\"] == 2][\"Company Name\\n.1\"]\n",
    "three_coops = df[df[\"NumInternships\"] == 3][\"Company Name\\n.2\"]\n",
    "four_coops = df[df[\"NumInternships\"] == 4][\"Company Name\\n.3\"]\n",
    "five_coops = df[df[\"NumInternships\"] == 5][\"Company Name\\n.4\"]\n",
    "six_coops = df[df[\"NumInternships\"] == 6][\"Company Name\\n.5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_coops.append(two_coops).append(three_coops).append(four_coops).append(five_coops).append(six_coops).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What places hire a lot of interns who return?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Think about whether we want to use .loc instead \n",
    "return0 = df[df[\"Company Name\\n.1\"] ==  df[\"Company Name\\n\"]][\"Company Name\\n\"]\n",
    "return1 = df[df[\"Company Name\\n.2\"] ==  df[\"Company Name\\n.1\"]][\"Company Name\\n.1\"]\n",
    "return2 = df[df[\"Company Name\\n.3\"] ==  df[\"Company Name\\n.2\"]][\"Company Name\\n.2\"]\n",
    "return3 = df[df[\"Company Name\\n.4\"] ==  df[\"Company Name\\n.3\"]][\"Company Name\\n.3\"]\n",
    "return4 = df[df[\"Company Name\\n.5\"] ==  df[\"Company Name\\n.4\"]][\"Company Name\\n.4\"]\n",
    "return0.append(return1).append(return2).append(return3).append(return4).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key insights: \n",
    "- Shopify is probably a good place for first years to apply - they hire many waterloo kids, many first year waterloo kids, and people are happy there\n",
    "- If I don't get google or Cali for my first co-op, that's pretty common. In fact, most first co-ops work in Canada companies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Help me understand what a data scientist does \n",
    "People like to hype up machine learning. What do machine learning interns do? Is that something I'm interested in? Let's use data to find out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a DS anyway? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_data = df[df[\"Type\\n\"]== \"ds\"][['Skills (list all skills as distinct words)', 'Job Roles (May be large paragraph)\\n', 'Job Roles (May be large paragraph)\\n.1', 'Job Roles (May be large paragraph)\\n.2', 'Job Roles (May be large paragraph)\\n.3', 'Job Roles (May be large paragraph)\\n.4', 'Job Roles (May be large paragraph)\\n.5','Project Description','Project Description.1','Project Description.2','Project Description.3','Project Description.4']]\n",
    "ds_data.to_csv(\"ds_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do I need to move to the States become a DS? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_people = df[df[\"Type\\n\"]==\"ds\"]\n",
    "non_ds_people = df[df[\"Type\\n\"]!=\"ds\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job0 = ds_people.loc[~ds_people[\"Company Name\\n\"].isnull(),\"is_us_0\"]\n",
    "job1 = ds_people.loc[~ds_people[\"Company Name\\n.1\"].isnull(),\"is_us_1\"]\n",
    "job2 = ds_people.loc[~ds_people[\"Company Name\\n.2\"].isnull(),\"is_us_2\"]\n",
    "job3 = ds_people.loc[~ds_people[\"Company Name\\n.3\"].isnull(),\"is_us_3\"]\n",
    "job4 = ds_people.loc[~ds_people[\"Company Name\\n.4\"].isnull(),\"is_us_4\"]\n",
    "job5 = ds_people.loc[~ds_people[\"Company Name\\n.5\"].isnull(),\"is_us_5\"]\n",
    "ds_jobs = job0.append(job1).append(job2).append(job3).append(job4).append(job5)\n",
    "ds_jobs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job0 = non_ds_people.loc[~non_ds_people[\"Company Name\\n\"].isnull(),\"is_us_0\"]\n",
    "job1 = non_ds_people.loc[~non_ds_people[\"Company Name\\n.1\"].isnull(),\"is_us_1\"]\n",
    "job2 = non_ds_people.loc[~non_ds_people[\"Company Name\\n.2\"].isnull(),\"is_us_2\"]\n",
    "job3 = non_ds_people.loc[~non_ds_people[\"Company Name\\n.3\"].isnull(),\"is_us_3\"]\n",
    "job4 = non_ds_people.loc[~non_ds_people[\"Company Name\\n.4\"].isnull(),\"is_us_4\"]\n",
    "job5 = non_ds_people.loc[~non_ds_people[\"Company Name\\n.5\"].isnull(),\"is_us_5\"]\n",
    "non_ds_jobs = job0.append(job1).append(job2).append(job3).append(job4).append(job5)\n",
    "non_ds_jobs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 / (18+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "63 / (101 + 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of internships of DS and non DS people \n",
    "ds_people[\"NumInternships\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What skills do DS people know? \n",
    "There really isn't any new commands here. Just copy paste a previous command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = ds_people[\"Skills (list all skills as distinct words)\"]\n",
    "skills = skills.loc[~skills.isnull()]\n",
    "# This last command is kinda challenging, think about how to show em how to write \n",
    "ranked_skills_list = skills.apply(lambda x: pd.value_counts(x.split(\",\"))).sum(axis = 0).sort_values(ascending=False)\n",
    "ranked_skills_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Understanding limitations in our data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly talk about how the data was collected (google search \"uwaterloo intern filetype:pdf\"). Then copy em to a spreadsheet. Probably convert this to an MC question and ask people? \n",
    "#### Questions that we cannot answer given our data: \n",
    "- Are UW students more likely to work in USA than UofT students? (Missing data) \n",
    "- Are DS people more likely to have personal websites than SWE people? (bad data collection method, implies everyone has website)\n",
    "- Do people with lower grades have less chances of getting PM? (not enough clear grade / GPA data) \n",
    "- Do short people have better jobs than tall people? (require causation, correlation is not useful) \n",
    "- When applying to Microsoft, does being in SYDE put you at a disadvantage? (causation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Summary: \n",
    "\n",
    "- Understanding data is not always intuitive. Data Analysts extract value ouf of data, which is not always easy   \n",
    "- Small improvements may have large downstream impacts (10% drop in rejections -> double # interviews) \n",
    "- Pandas and numpy deal with matricies (which are arrays of arrays). Manipulating these arrays help us extract information\n",
    "- Data analytics typically involves cleaning data before trying to extract value\n",
    "- Plotting is possible with MatPlot lib \n",
    "- We can extract value from both text and non-text data \n",
    "- Sometimes we may come to false conclusions from our data. We need to carefully think about our results and try to avoid\n",
    "- Sometimes, our questions cannot be answered from our data. In which case, we probably will need to collect more data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to count skills - This won't be used \n",
    "# Clean - Will probably be provided\n",
    "skillCounter = pd.DataFrame(skills, index=[\"count\"])\n",
    "\n",
    "for skilllist in df[\"Skills (list all skills as distinct words)\"]:\n",
    "    for k, v in skillCounter.items():\n",
    "        if \" \"+k+\" \" in skilllist or  \" \"+k+\", \" in skilllist:\n",
    "            skillCounter[k] = skillCounter[k] + 1\n",
    "    \n",
    "skillCounter.transpose().sort_values([\"count\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternative way to count skills - This won't be used \n",
    "# Clean - Will probably be provided\n",
    "df[\"Skills (list all skills as distinct words)\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Get a list of skills\n",
    "skillsCount = {}\n",
    "for skilllist in df[\"Skills (list all skills as distinct words)\"]:\n",
    "    skills = skilllist.split(\",\")\n",
    "    if len(skilllist) < 5:\n",
    "        continue\n",
    "    for skill in skills:\n",
    "        skill=skill.strip()\n",
    "        skillsCount[skill] = skillsCount.get(skill, 0) + 1\n",
    "skills = {k: 0 for k, v in sorted(skillsCount.items(), key=lambda x:x[1], reverse=True) if v >= 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skillCounter = pd.DataFrame(skills, index=[\"count\"])\n",
    "\n",
    "jobs = df[\"Job Roles (May be large paragraph)\\n\"]\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.1\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.2\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.3\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.4\"], ignore_index=True)\n",
    "jobs = jobs.append(df[\"Job Roles (May be large paragraph)\\n.5\"], ignore_index=True)\n",
    "jobs = jobs.dropna()\n",
    "\n",
    "for skilllist in jobs:\n",
    "    skilllist = skilllist.lower()\n",
    "    for k, v in skillCounter.items():\n",
    "        if \" \"+k+\", \" in skilllist or \" \"+k+\" \" in skilllist:\n",
    "            skillCounter[k] = skillCounter[k] + 1\n",
    "    \n",
    "skillCounter.transpose().sort_values([\"count\"], ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
